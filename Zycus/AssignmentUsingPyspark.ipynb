{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a6535a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ca6299-88bc-462e-965c-4124c3269f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "580609c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3bc5faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(master=\"local[2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "018c4f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# df = spark.sql(\"select 'spark' as hello \")\n",
    "\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3779c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc = spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1325009f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=pyspark-shell>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7affbfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"TextClassifierApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc37cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\gprak\\Downloads\\projects\\Data\\86b13d9a4b8e11ec\\project\\training_data.csv\"\n",
    "df = spark.read.csv(path,header=True,inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0115bf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               title|            category|\n",
      "+--------------------+--------------------+\n",
      "|    The Three Amigos|                None|\n",
      "|Home Essentials B...|      Home & Kitchen|\n",
      "|Cooper Wiring Qui...|Tools & Home Impr...|\n",
      "|Baseboarders&reg;...|Tools & Home Impr...|\n",
      "|The Great Wave Of...|     Office Products|\n",
      "|Nemcor Pittsburgh...|      Home & Kitchen|\n",
      "|Patrician Berkley...|                None|\n",
      "|SouvNear 81461402...|                None|\n",
      "|20 Qty. Halco 50W...|Tools & Home Impr...|\n",
      "|      Rilakkuma Bowl|                None|\n",
      "|Redbirdlinen 1pc ...|      Home & Kitchen|\n",
      "|Hospital Bath Tow...|      Home & Kitchen|\n",
      "|Symphony in Red a...|      Home & Kitchen|\n",
      "|Big Train BLENDED...|Grocery & Gourmet...|\n",
      "|Surpahs Round 11 ...|      Home & Kitchen|\n",
      "|Mikasa Love Story...|                None|\n",
      "|180 Snacks Nutty ...|                None|\n",
      "|Anti-Slip Handle ...|      Home & Kitchen|\n",
      "|Imagine Thicket G...|                None|\n",
      "|KOHLER K-3754-96 ...|                None|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c4ce11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title', 'category']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5938e47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "185a891b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title', 'category']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "82fde9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.ml.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b202f841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Binarizer',\n",
       " 'BucketedRandomProjectionLSH',\n",
       " 'BucketedRandomProjectionLSHModel',\n",
       " 'Bucketizer',\n",
       " 'ChiSqSelector',\n",
       " 'ChiSqSelectorModel',\n",
       " 'CountVectorizer',\n",
       " 'CountVectorizerModel',\n",
       " 'DCT',\n",
       " 'ElementwiseProduct',\n",
       " 'FeatureHasher',\n",
       " 'HasFeaturesCol',\n",
       " 'HasHandleInvalid',\n",
       " 'HasInputCol',\n",
       " 'HasInputCols',\n",
       " 'HasLabelCol',\n",
       " 'HasMaxIter',\n",
       " 'HasNumFeatures',\n",
       " 'HasOutputCol',\n",
       " 'HasOutputCols',\n",
       " 'HasRelativeError',\n",
       " 'HasSeed',\n",
       " 'HasStepSize',\n",
       " 'HasThreshold',\n",
       " 'HasThresholds',\n",
       " 'HashingTF',\n",
       " 'IDF',\n",
       " 'IDFModel',\n",
       " 'Imputer',\n",
       " 'ImputerModel',\n",
       " 'IndexToString',\n",
       " 'Interaction',\n",
       " 'JavaEstimator',\n",
       " 'JavaMLReadable',\n",
       " 'JavaMLWritable',\n",
       " 'JavaModel',\n",
       " 'JavaParams',\n",
       " 'JavaTransformer',\n",
       " 'MaxAbsScaler',\n",
       " 'MaxAbsScalerModel',\n",
       " 'MinHashLSH',\n",
       " 'MinHashLSHModel',\n",
       " 'MinMaxScaler',\n",
       " 'MinMaxScalerModel',\n",
       " 'NGram',\n",
       " 'Normalizer',\n",
       " 'OneHotEncoder',\n",
       " 'OneHotEncoderModel',\n",
       " 'PCA',\n",
       " 'PCAModel',\n",
       " 'Param',\n",
       " 'Params',\n",
       " 'PolynomialExpansion',\n",
       " 'QuantileDiscretizer',\n",
       " 'RFormula',\n",
       " 'RFormulaModel',\n",
       " 'RegexTokenizer',\n",
       " 'RobustScaler',\n",
       " 'RobustScalerModel',\n",
       " 'SQLTransformer',\n",
       " 'SparkContext',\n",
       " 'StandardScaler',\n",
       " 'StandardScalerModel',\n",
       " 'StopWordsRemover',\n",
       " 'StringIndexer',\n",
       " 'StringIndexerModel',\n",
       " 'Tokenizer',\n",
       " 'TypeConverters',\n",
       " 'UnivariateFeatureSelector',\n",
       " 'UnivariateFeatureSelectorModel',\n",
       " 'VarianceThresholdSelector',\n",
       " 'VarianceThresholdSelectorModel',\n",
       " 'VectorAssembler',\n",
       " 'VectorIndexer',\n",
       " 'VectorIndexerModel',\n",
       " 'VectorSizeHint',\n",
       " 'VectorSlicer',\n",
       " 'Word2Vec',\n",
       " 'Word2VecModel',\n",
       " '_BucketedRandomProjectionLSHParams',\n",
       " '_CountVectorizerParams',\n",
       " '_IDFParams',\n",
       " '_ImputerParams',\n",
       " '_LSH',\n",
       " '_LSHModel',\n",
       " '_LSHParams',\n",
       " '_MaxAbsScalerParams',\n",
       " '_MinMaxScalerParams',\n",
       " '_OneHotEncoderParams',\n",
       " '_PCAParams',\n",
       " '_RFormulaParams',\n",
       " '_RobustScalerParams',\n",
       " '_Selector',\n",
       " '_SelectorModel',\n",
       " '_SelectorParams',\n",
       " '_StandardScalerParams',\n",
       " '_StringIndexerParams',\n",
       " '_UnivariateFeatureSelectorParams',\n",
       " '_VarianceThresholdSelectorParams',\n",
       " '_VectorIndexerParams',\n",
       " '_Word2VecParams',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_convert_to_vector',\n",
       " '_jvm',\n",
       " 'inherit_doc',\n",
       " 'keyword_only',\n",
       " 'since']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pyspark.ml.feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2bc7a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer,StopWordsRemover,CountVectorizer,IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2ccdf26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fb1e1861",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol='title',outputCol='mytokens')\n",
    "stopwords_remover = StopWordsRemover(inputCol='mytokens',outputCol='filtered_tokens')\n",
    "vectorizer = CountVectorizer(inputCol='filtered_tokens',outputCol='rawFeatures')\n",
    "idf = IDF(inputCol='rawFeatures',outputCol='vectorizedFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f0ab35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = StringIndexer(inputCol='category',outputCol='label').fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9dc2bb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|               title|            category|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|    The Three Amigos|                None|  0.0|\n",
      "|Home Essentials B...|      Home & Kitchen|  1.0|\n",
      "|Cooper Wiring Qui...|Tools & Home Impr...|  2.0|\n",
      "|Baseboarders&reg;...|Tools & Home Impr...|  2.0|\n",
      "|The Great Wave Of...|     Office Products|  3.0|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelEncoder.transform(df).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "03b95145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_dict = {'Web Development':0.0,\n",
    "#  'Business Finance':1.0,\n",
    "#  'Musical Instruments':2.0,\n",
    "#  'Graphic Design':3.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7cae002",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = labelEncoder.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53bc1a64-cb0d-4400-b0a0-7ab83ae66f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|               title|            category|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|    The Three Amigos|                None|  0.0|\n",
      "|Home Essentials B...|      Home & Kitchen|  1.0|\n",
      "|Cooper Wiring Qui...|Tools & Home Impr...|  2.0|\n",
      "|Baseboarders&reg;...|Tools & Home Impr...|  2.0|\n",
      "|The Great Wave Of...|     Office Products|  3.0|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3dffc712-32b6-4fd8-80f3-3b2f25a36117",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.filter(\"category != 'None'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "60d5fbea-21b7-43b7-8fca-a836bdcf3fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|               title|            category|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|Home Essentials B...|      Home & Kitchen|  1.0|\n",
      "|Cooper Wiring Qui...|Tools & Home Impr...|  2.0|\n",
      "|Baseboarders&reg;...|Tools & Home Impr...|  2.0|\n",
      "|The Great Wave Of...|     Office Products|  3.0|\n",
      "|Nemcor Pittsburgh...|      Home & Kitchen|  1.0|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4b57a2d2-1b57-4564-b9b4-9d46c001d8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10067"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8d0e884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainDF,testDF) = df.randomSplit((0.7,0.3),seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2f933455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "25ee86ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol='vectorizedFeatures',labelCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dd14f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ed2a4a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[tokenizer,stopwords_remover,vectorizer,idf,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "807097f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "efa8c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_model.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "be7bfaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|               title|            category|label|            mytokens|     filtered_tokens|         rawFeatures|  vectorizedFeatures|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "| BAZIC Sports Pus...|     Office Products|  3.0|[, bazic, sports,...|[, bazic, sports,...|(22831,[13,37,46,...|(22831,[13,37,46,...|[-3.6123809322418...|[8.02262906045998...|       3.0|\n",
      "| Biedermann &amp;...|      Home & Kitchen|  1.0|[, biedermann, &a...|[, biedermann, &a...|(22831,[5,28,36,4...|(22831,[5,28,36,4...|[-3.6177162823991...|[2.14357793084081...|       1.0|\n",
      "| Bosco Chocolate ...|Grocery & Gourmet...|  4.0|[, bosco, chocola...|[, bosco, chocola...|(22831,[0,24,46,7...|(22831,[0,24,46,7...|[-3.6166644152096...|[1.86825934222308...|       4.0|\n",
      "| Bulk Nuts Organi...|Grocery & Gourmet...|  4.0|[, bulk, nuts, or...|[, bulk, nuts, or...|(22831,[34,46,162...|(22831,[34,46,162...|[-3.6023739291447...|[3.62586254494038...|       4.0|\n",
      "| Coaster Contempo...|      Home & Kitchen|  1.0|[, coaster, conte...|[, coaster, conte...|(22831,[30,46,70,...|(22831,[30,46,70,...|[-3.6225852870114...|[2.18134258266067...|       1.0|\n",
      "| Conversation Con...|      Home & Kitchen|  1.0|[, conversation, ...|[, conversation, ...|(22831,[27,46,72,...|(22831,[27,46,72,...|[-3.6288732627192...|[2.65979726232791...|       1.0|\n",
      "| Coutellerie Tarr...|      Home & Kitchen|  1.0|[, coutellerie, t...|[, coutellerie, t...|(22831,[2,21,28,4...|(22831,[2,21,28,4...|[-3.6225072507470...|[6.76621847742010...|       1.0|\n",
      "| Crystal Flame Co...|      Home & Kitchen|  1.0|[, crystal, flame...|[, crystal, flame...|(22831,[25,46,117...|(22831,[25,46,117...|[-3.6173807476387...|[7.11279118260594...|       1.0|\n",
      "| Design Toscano G...|     Office Products|  3.0|[, design, toscan...|[, design, toscan...|(22831,[46,55,131...|(22831,[46,55,131...|[-3.6257410157263...|[6.26283258921556...|       3.0|\n",
      "| Elrene Home Fash...|      Home & Kitchen|  1.0|[, elrene, home, ...|[, elrene, home, ...|(22831,[0,1,15,46...|(22831,[0,1,15,46...|[-3.6172269391606...|[1.93243281340478...|       1.0|\n",
      "| Farberware Basic...|      Home & Kitchen|  1.0|[, farberware, ba...|[, farberware, ba...|(22831,[46,152,75...|(22831,[46,152,75...|[-3.6307885019217...|[2.72052933312863...|       1.0|\n",
      "| Genie 34538S.S D...|Industrial & Scie...|  5.0|[, genie, 34538s....|[, genie, 34538s....|(22831,[0,46,274,...|(22831,[0,46,274,...|[-3.6283998681395...|[1.69818063914565...|       2.0|\n",
      "| Ginsu Hanaita Se...|      Home & Kitchen|  1.0|[, ginsu, hanaita...|[, ginsu, hanaita...|(22831,[2,9,21,46...|(22831,[2,9,21,46...|[-3.6182303701957...|[5.39347957516664...|       2.0|\n",
      "| HANGERWORLD Pack...|      Home & Kitchen|  1.0|[, hangerworld, p...|[, hangerworld, p...|(22831,[0,5,13,44...|(22831,[0,5,13,44...|[-3.6039156798953...|[2.97440789135385...|       1.0|\n",
      "| Hansen&#39;s Sod...|Grocery & Gourmet...|  4.0|[, hansen&#39;s, ...|[, hansen&#39;s, ...|(22831,[8,46,303,...|(22831,[8,46,303,...|[-3.6085718373965...|[2.41007839808501...|       4.0|\n",
      "| Hong Tze Collect...|      Home & Kitchen|  1.0|[, hong, tze, col...|[, hong, tze, col...|(22831,[46,1520,1...|(22831,[46,1520,1...|[-3.6252449272182...|[1.74920464849126...|       1.0|\n",
      "| Hydrofarm Active...|Tools & Home Impr...|  2.0|[, hydrofarm, act...|[, hydrofarm, act...|(22831,[37,46,157...|(22831,[37,46,157...|[-3.6204435969311...|[2.81161605667118...|       1.0|\n",
      "| Lexmark X5650 Al...|     Office Products|  3.0|[, lexmark, x5650...|[, lexmark, x5650...|(22831,[46,603,20...|(22831,[46,603,20...|[-3.6108926356534...|[5.43146969265172...|       3.0|\n",
      "| Mama Leone&#39;s...|Grocery & Gourmet...|  4.0|[, mama, leone&#3...|[, mama, leone&#3...|(22831,[8,31,46,1...|(22831,[8,31,46,1...|[-3.6206857672327...|[1.42514977413609...|       4.0|\n",
      "| Mayline Brighton...|      Home & Kitchen|  1.0|[, mayline, brigh...|[, mayline, brigh...|(22831,[46,114,66...|(22831,[46,114,66...|[-3.6211286051103...|[1.43168111849145...|       1.0|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9b5a237c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title',\n",
       " 'category',\n",
       " 'label',\n",
       " 'mytokens',\n",
       " 'filtered_tokens',\n",
       " 'rawFeatures',\n",
       " 'vectorizedFeatures',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9661cb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----+----------+\n",
      "|       rawPrediction|         probability|            category|label|prediction|\n",
      "+--------------------+--------------------+--------------------+-----+----------+\n",
      "|[-3.6123809322418...|[8.02262906045998...|     Office Products|  3.0|       3.0|\n",
      "|[-3.6177162823991...|[2.14357793084081...|      Home & Kitchen|  1.0|       1.0|\n",
      "|[-3.6166644152096...|[1.86825934222308...|Grocery & Gourmet...|  4.0|       4.0|\n",
      "|[-3.6023739291447...|[3.62586254494038...|Grocery & Gourmet...|  4.0|       4.0|\n",
      "|[-3.6225852870114...|[2.18134258266067...|      Home & Kitchen|  1.0|       1.0|\n",
      "|[-3.6288732627192...|[2.65979726232791...|      Home & Kitchen|  1.0|       1.0|\n",
      "|[-3.6225072507470...|[6.76621847742010...|      Home & Kitchen|  1.0|       1.0|\n",
      "|[-3.6173807476387...|[7.11279118260594...|      Home & Kitchen|  1.0|       1.0|\n",
      "|[-3.6257410157263...|[6.26283258921556...|     Office Products|  3.0|       3.0|\n",
      "|[-3.6172269391606...|[1.93243281340478...|      Home & Kitchen|  1.0|       1.0|\n",
      "+--------------------+--------------------+--------------------+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select('rawPrediction','probability','category','label','prediction').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "58e12ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e5c81f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='label',predictionCol='prediction',metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "752cdf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e0140e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7675694206376414"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e600d3b2",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "11b21aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspark.ml.tuning as tune\n",
    "\n",
    "# # Create the parameter grid\n",
    "# grid = tune.ParamGridBuilder()\n",
    "\n",
    "# # Add the hyperparameter\n",
    "# grid = grid.addGrid(lr.regParam, np.arange(0, .1, .01))\n",
    "# grid = grid.addGrid(lr.elasticNetParam, [0, 1])\n",
    "\n",
    "# # Build the grid\n",
    "# grid = grid.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "09d57e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title', 'category', 'label']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bc5822c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CrossValidator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "# cv = tune.CrossValidator(estimator=lr, estimatorParamMaps=grid, evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "42445c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# #training_data = trainDF\n",
    "# #testing_data = testDF\n",
    "\n",
    "# paramGrid = ParamGridBuilder().addGrid(lr.regParam,[0.02,0.08])\\\n",
    "#             .addGrid(lr.elasticNetParam,[0.2,0.6]).build()\n",
    "\n",
    "# #evaluator_lr = MulticlassClassificationEvaluator(labelCol='label', metricName='accuracy')\n",
    "# evaluator_lr = evaluator\n",
    "# crossval = CrossValidator(estimator=lr,\n",
    "#                           estimatorParamMaps=paramGrid,\n",
    "#                           evaluator=evaluator_lr,\n",
    "#                           numFolds=2)\n",
    "\n",
    "# #start_time = time()\n",
    "# pipeline2 = Pipeline(stages=[tokenizer,stopwords_remover,vectorizer,idf])\n",
    "# piped_data = pipeline2.fit(df).transform(df)\n",
    "\n",
    "# # Split the data into training and test sets\n",
    "# training, test = piped_data.randomSplit([.7, .3])\n",
    "\n",
    "# #best_lr = lr.fit(training)\n",
    "\n",
    "# # # Print best_lr\n",
    "# #print(best_lr)\n",
    "\n",
    "# # Run cross-validation, and choose the best set of parameters.\n",
    "# cvModel = crossval.fit(training)\n",
    "\n",
    "# #end_time = time()\n",
    "\n",
    "# #training_time = end_time - start_time\n",
    "\n",
    "# #print(\"The time taken to train the data is: %0.3f seconds\" %training_time)\n",
    "\n",
    "# # Make predictions on testing data and calculating ROC metrics and model accuracy. \n",
    "# prediction = cvModel.transform(test)\n",
    "# # #output= prediction.select(\"features\",  \"probability\", \"prediction\")\n",
    "# # output = prediction\n",
    "# # acc = evaluator_lr.evaluate(output, {evaluator_lr.metricName: \"accuracy\"})\n",
    "# # f1 = evaluator_lr.evaluate(output, {evaluator_lr.metricName: \"f1\"})\n",
    "# # weightedPrecision = evaluator_lr.evaluate(output, {evaluator_lr.metricName: \"weightedPrecision\"})\n",
    "# # weightedRecall = evaluator_lr.evaluate(output, {evaluator_lr.metricName: \"weightedRecall\"})\n",
    "# # auc = evaluator_lr.evaluate(output)\n",
    "\n",
    "# # print(acc)\n",
    "# # print(f1)\n",
    "# # print(weightedPrecision)\n",
    "# # print(weightedRecall)\n",
    "# # print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cf21e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = prediction\n",
    "# acc = evaluator_lr.evaluate(output, {evaluator_lr.metricName: \"accuracy\"})\n",
    "# f1 = evaluator_lr.evaluate(output, {evaluator_lr.metricName: \"f1\"})\n",
    "# weightedPrecision = evaluator_lr.evaluate(output, {evaluator_lr.metricName: \"weightedPrecision\"})\n",
    "# weightedRecall = evaluator_lr.evaluate(output, {evaluator_lr.metricName: \"weightedRecall\"})\n",
    "# auc = evaluator_lr.evaluate(output)\n",
    "\n",
    "# print(acc)\n",
    "# print(f1)\n",
    "# print(weightedPrecision)\n",
    "# print(weightedRecall)\n",
    "# print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60f4f64",
   "metadata": {},
   "source": [
    "# Step 3. Create a Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dff9bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# from pyspark.ml.feature import OneHotEncoder, VectorAssembler, StringIndexer\n",
    "# from pyspark.ml import Pipeline\n",
    "# from pyspark.sql.functions import udf, StringType\n",
    "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# from pyspark.ml.classification import MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b57833e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=df\n",
    "# print(df.count())\n",
    "# train, validation, test = data.randomSplit([0.7, 0.1, 0.3], 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "52df39d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_columns = [item[0] for item in data.dtypes if item[1].startswith(\n",
    "#     'string')]\n",
    "# numeric_columns = [item[0] for item in data.dtypes if item[1].startswith(\n",
    "#     'double')]\n",
    "# indexers = [StringIndexer(inputCol=column, outputCol='{0}_index'.format(\n",
    "#     column)) for column in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8296ded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8d7d0779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [indexer.getOutputCol() for indexer in indexers] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2525c6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# featuresCreator = VectorAssembler(\n",
    "#     inputCols=[indexer.getOutputCol() for indexer in indexers] + numeric_columns,\n",
    "#     outputCol='features')\n",
    "# layers = [len(featuresCreator.getInputCols()), 40, 20, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "de678e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a973f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = MultilayerPerceptronClassifier(labelCol='label',\n",
    "#                                             featuresCol='features',\n",
    "#                                             maxIter=100,\n",
    "#                                             layers=layers,\n",
    "#                                             blockSize=128,\n",
    "#                                             seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "952aedb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline(stages=indexers + [featuresCreator, classifier])\n",
    "# model = pipeline.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1a9d9faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_output_df = model.transform(train)\n",
    "# validation_output_df = model.transform(validation)\n",
    "# test_output_df = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3cbab388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_predictionAndLabels = train_output_df.select('prediction', 'label')\n",
    "# validation_predictionAndLabels = validation_output_df.select('prediction', 'label')\n",
    "# test_predictionAndLabels = test_output_df.select('prediction', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "333464a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = ['weightedPrecision', 'weightedRecall', 'accuracy']\n",
    "# for metric in metrics:\n",
    "#     evaluator = MulticlassClassificationEvaluator(metricName=metric)\n",
    "#     print('Train ' + metric + ' = ' + str(evaluator.evaluate(train_predictionAndLabels)))\n",
    "#     # print('Validation ' + metric + ' = ' + str(evaluator.evaluate(validation_predictionAndLabels)))\n",
    "#     # pr/int('Test ' + metric + ' = ' + str(evaluator.evaluate(test_predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108652d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813d6ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
